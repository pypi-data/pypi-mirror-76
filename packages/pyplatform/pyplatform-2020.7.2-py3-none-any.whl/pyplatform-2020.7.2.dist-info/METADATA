Metadata-Version: 2.1
Name: pyplatform
Version: 2020.7.2
Summary: Pyplatform provides wrapper functions for using Google BigQuery as datawarehouse and creating data pipelines involving Google Cloud, Microsoft Azure, O365, and Tableau Server as source and destination.
Home-page: https://github.com/mhadi813/pyplatform
Author: Muhammad Hadi
Author-email: mhadi813@gmail.com
License: BSD
Keywords: google bigquery cloud functions storage jupyterlab python SQL
Platform: UNKNOWN
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Topic :: Office/Business
Classifier: License :: OSI Approved :: BSD License
Classifier: Programming Language :: Python :: 3.6
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Description-Content-Type: text/markdown
Requires-Dist: pyplatform-datawarehouse
Requires-Dist: pyplatform-database
Requires-Dist: pyplatform-datalake
Requires-Dist: pyplatform-reporting
Requires-Dist: pyplatform-common

### Pyplatform provides wrapper functions for using Google BigQuery as datawarehouse and creating data pipelines involving Google Cloud, Microsoft Azure, O365, and Tableau Server as source and destination.

### [the platorm architecture:](https://storage.cloud.google.com/public_images_py/pyplatform_image/pyplatform.png)
-  enables fast and scalable SQL datawarehousing service
-  abstracts away the infrastuture by builiding data pipelines with serverless compute solutions in python runtime environments
-  simplifies development environment by using jupyter lab as the main tool
<img align="left" style="width: 1200px;" src="https://raw.githubusercontent.com/mhadi813/pyplatform/master/samples/image/pyplatform.png">

## Installation
```python
pip install pyplatform
```

## Setting up development environment
```
git clone https://github.com/mhadi813/pyplatform
cd pyplatform
conda env create -f pyplatform_dev.yml
```

### [Environment variables](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#saving-environment-variables)
```python
import os

os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'path/to/default_service_account.json'
os.environ['DATASET'] = 'default_bigquery_dataset_name'
os.environ['STORAGE_BUCKET'] = 'default_storage_bucket_id'
```

## Usage
## common data pipeline architectures:

### - [Http sources](https://storage.cloud.google.com/public_images_py/pyplatform_image/http_sources.png)
<img align="left" style="width: 740px;" src="https://raw.githubusercontent.com/mhadi813/pyplatform/master/samples/image/http_sources.png">

### - [On-prem servers](https://storage.cloud.google.com/public_images_py/pyplatform_image/on-prem_sources.png)
<img align="left" style="width: 740px;" src="https://raw.githubusercontent.com/mhadi813/pyplatform/master/samples/image/on-prem_sources.png">

### - [Bigquery integration with Azure Logic Apps](https://storage.cloud.google.com/public_images_py/pyplatform_image/logic_apps_integration.png)
<img align="left" style="width: 740px;" src="https://raw.githubusercontent.com/mhadi813/pyplatform/master/samples/image/logic_apps_integration.png">

### - [Event driven ETL process](https://storage.cloud.google.com/public_images_py/pyplatform_image/event_driven.png)
<img align="left" style="width: 740px;" src="https://raw.githubusercontent.com/mhadi813/pyplatform/master/samples/image/event_driven.png">

### - [Streaming pipelines](https://storage.cloud.google.com/public_images_py/pyplatform_image/streaming.png)
<img align="left" style="width: 740px;" src="https://raw.githubusercontent.com/mhadi813/pyplatform/master/samples/image/streaming.png">

## Exploring modules
```python

import pyplatform as pyp
pyp.show_me()

```



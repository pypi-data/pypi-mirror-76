Metadata-Version: 2.1
Name: pytorch-adaptive-computation-time
Version: 0.1.2
Summary: Implements adaptive computation time RNNs in PyTorch, with the same interface as builtin RNNs.
Home-page: https://github.com/maxwells-daemons/pytorch-adaptive-computation-time
License: Apache-2.0
Keywords: pytorch,adaptive-computation-time,rnn,machine-learning,neural-network
Author: maxwells-daemons
Author-email: aidanswope@gmail.com
Requires-Python: >=3.6.10,<4.0.0
Classifier: Environment :: GPU
Classifier: Environment :: GPU :: NVIDIA CUDA
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Natural Language :: English
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Topic :: Scientific/Engineering
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development :: Libraries
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Typing :: Typed
Provides-Extra: docs
Requires-Dist: pytorch-lightning (==0.8.5)
Requires-Dist: sphinx (>=3.2.0,<4.0.0); extra == "docs"
Requires-Dist: sphinx-argparse (>=0.2.5,<0.3.0); extra == "docs"
Requires-Dist: torch (>=1.5.0,<2.0.0)
Project-URL: Documentation, https://pytorch-adaptive-computation-time.readthedocs.io/en/latest/
Project-URL: Repository, https://github.com/maxwells-daemons/pytorch-adaptive-computation-time
Description-Content-Type: text/markdown

# pytorch-adaptive-computation-time

This library implements PyTorch modules for recurrent neural networks that can learn to execute variable-time algorithms,
as presented in [Adaptive Computation Time for Recurrent Neural Networks (Graves 2016)](https://arxiv.org/abs/1603.08983/).
These models can learn patterns requiring varying amounts of computation for a fixed-size input,
which is difficult or impossible for traditional neural networks.
The library aims to be clean, idiomatic, and extensible, offering a similar interface to PyTorch’s builtin recurrent modules.

The main features are:
 - A nearly drop-in replacement for torch.nn.RNN- and torch.nn.RNNCell-style RNNs, but with the power of variable computation time.
 - A wrapper which adds adaptive computation time to any RNNCell.
 - Data generators, configs, and training scripts to reproduce experiments from the paper.

## Example
Vanilla PyTorch GRU:

```
rnn = torch.nn.GRU(64, 128, num_layers=2)
output, hidden = rnn(inputs, initial_hidden)
```

GRU with adaptive computation time:

```
rnn = models.AdaptiveGRU(64, 128, num_layers=2, time_penalty=1e-3)
output, hidden, ponder_cost = rnn(inputs, initial_hidden)
```

## Documentation
Documentation is [hosted on Read the Docs](https://github.com/iamishalkin/cyrtd).

## BibTeX

You don’t need to cite this code, but if it helps you in your research and you’d like to:

```
@misc{swope2020ACT,
  title   = "pytorch-adaptive-computation-time",
  author  = "Swope, Aidan",
  journal = "GitHub",
  year    = "2020",
  url     = "https://github.com/maxwells-daemons/pytorch-adaptive-computation-time"
}
```

If you use the experiment code, please also consider [citing PyTorch Lightning](https://github.com/PyTorchLightning/pytorch-lightning#bibtex/).


{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatically selecting a naive model to use as a benchmark\n",
    "\n",
    "forecast-tools provides a `auto_naive` function that uses point-forecast cross validation to select the 'best' naive model to use as a benchmark.  \n",
    "\n",
    "The function tests all of the naive `Forecast` methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forecast_tools.datasets import load_emergency_dept\n",
    "from forecast_tools.model_selection import auto_naive                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function auto_naive in module forecast_tools.model_selection:\n",
      "\n",
      "auto_naive(y_train, horizon=1, seasonal_period=1, min_train_size='auto', method='cv', step=1, window_size='auto', metric='mae')\n",
      "    Automatic selection of the 'best' naive benchmark on a 'single' series\n",
      "    \n",
      "    The selection process uses out-of-sample cv performance.\n",
      "    \n",
      "    By default auto_naive uses cross validation to estimate the mean\n",
      "    point forecast peformance of all naive methods.  It selects the method\n",
      "    with the lowest point forecast metric on average.\n",
      "    \n",
      "    If there is limited data for training a basic holdout sample could be\n",
      "    used.\n",
      "    \n",
      "    Dev note: the plan is to update this to work with multiple series.\n",
      "    It would be best to use MASE for multiple series comparison.\n",
      "    \n",
      "    Parameters:\n",
      "    ----------\n",
      "    y_train: array-like\n",
      "        training data.  typically in a pandas.Series, pandas.DataFrame\n",
      "        or numpy.ndarray format.\n",
      "    \n",
      "    horizon: int, optional (default=1)\n",
      "        Forecast horizon.\n",
      "    \n",
      "    seasonal_period: int, optional (default=1)\n",
      "        Frequency of the data.  E.g. 7 for weekly pattern, 12 for monthly\n",
      "        365 for daily.\n",
      "    \n",
      "    min_train_size: int or str, optional (default='auto')\n",
      "        The size of the initial training set (if method=='ro' or 'sw').\n",
      "        If 'auto' then then min_train_size is set to len(y_train) // 3\n",
      "        If main_train_size='auto' and method='holdout' then\n",
      "        min_train_size = len(y_train) - horizon.\n",
      "    \n",
      "    method: str, optional (default='cv')\n",
      "        out of sample selection method.\n",
      "        'ro' - rolling forecast origin\n",
      "        'sw' - sliding window\n",
      "        'cv' - scores from both ro and sw\n",
      "        'holdout' - single train/test split\n",
      "         Methods'ro' and 'sw' are similar, however, sw has a fixed\n",
      "         window_size and drops older data from training.\n",
      "    \n",
      "    step: int, optional (default=1)\n",
      "        The stride/step of the cross-validation. I.e. the number\n",
      "        of observations to move forward between folds.\n",
      "    \n",
      "    window_size: str or int, optional (default='auto')\n",
      "        The window_size if using sliding window cross validation\n",
      "        When 'auto' and method='sw' then\n",
      "        window_size=len(y_train) // 3\n",
      "    \n",
      "    metric: str, optional (default='mae')\n",
      "        The metric to measure out of sample accuracy.\n",
      "        Options: mase, mae, mape, smape, mse, rmse, me.\n",
      "    \n",
      "    Returns:\n",
      "    --------\n",
      "    dict\n",
      "        'model': baseline.Forecast\n",
      "        f'{metric}': float\n",
      "    \n",
      "        Contains the model and its CV performance.\n",
      "    \n",
      "    Raises:\n",
      "    -------\n",
      "    ValueError\n",
      "        For invalid method, metric, window_size parameters\n",
      "    \n",
      "    See Also:\n",
      "    --------\n",
      "    forecast_tools.baseline.Naive1\n",
      "    forecast_tools.baseline.SNaive\n",
      "    forecast_tools.baseline.Drift\n",
      "    forecast_tools.baseline.Average\n",
      "    forecast_tools.baseline.EnsembleNaive\n",
      "    forecast_tools.baseline.baseline_estimators\n",
      "    forecast_tools.model_selection.rolling_forecast_origin\n",
      "    forecast_tools.model_selection.sliding_window\n",
      "    forecast_tools.model_selection.mase_cross_validation_score\n",
      "    forecast_tools.metrics.mean_absolute_scaled_error\n",
      "    \n",
      "    Examples:\n",
      "    ---------\n",
      "    Measuring MAE and taking the best method using both\n",
      "    rolling origin and sliding window cross validation\n",
      "    of a 56 day forecast.\n",
      "    \n",
      "    >>> from forecast_tools.datasets import load_emergency_dept\n",
      "    >>> y_train = load_emergency_dept\n",
      "    >>> best = auto_naive(y_train, seasonal_period=7, horizon=56)\n",
      "    >>> best\n",
      "    {'model': Average(), 'mae': 19.63791579700355}\n",
      "    \n",
      "    \n",
      "    Take a step of 7 days between cv folds.\n",
      "    \n",
      "    >>> from forecast_tools.datasets import load_emergency_dept\n",
      "    >>> y_train = load_emergency_dept\n",
      "    >>> best = auto_naive(y_train, seasonal_period=7, horizon=56,\n",
      "        ...               step=7)\n",
      "    >>> best\n",
      "    {'model': Average(), 'mae': 19.675635558539383}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(auto_naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = load_emergency_dept()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the best naive model for a h-step horizon of 7 days.\n",
    "\n",
    "Let's select a method for the emergency deparment daily level to predict 7 days ahead.  By default the function using the **mean absolute error** to evaluate forecast accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': Average(), 'mae': 19.679856211931035}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = auto_naive(y_train, horizon=7, seasonal_period=7)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([221.06395349, 221.06395349, 221.06395349, 221.06395349,\n",
       "       221.06395349, 221.06395349, 221.06395349])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = best['model'].fit_predict(y_train, horizon=7)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a different forecasting error metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': Average(), 'mape': 8.69955926909263}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = auto_naive(y_train, horizon=7, seasonal_period=7, metric='mape')\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a single train-test split when data are limited.\n",
    "\n",
    "If your forecast horizon means that h-step cross-validation is infeasible then you can automatically select using a single holdout sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': Average(), 'mae': 30.182280627384486}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = auto_naive(y_train, horizon=7, seasonal_period=7, method='holdout')\n",
    "best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

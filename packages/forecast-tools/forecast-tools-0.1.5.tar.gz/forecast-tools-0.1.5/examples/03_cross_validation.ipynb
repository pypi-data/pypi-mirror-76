{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#suppress ARIMA warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up till now we have used a single validation period to select our best model.  The weakness of that approach is that it gives you a sample size of 1 (that's better than nothing, but generally poor statistics!).  Time series cross validation is an approach to provide more data points when comparing models. In the classicial time series literature time series cross validation is called a **Rolling Forecast Origin**.  There may also be benefit of taking a **sliding window** approach to cross validaiton.  This second approach maintains a fixed sized training set.  I.e. it drops older values from the time series during validation.\n",
    "\n",
    "## Rolling Forecast Origin\n",
    "\n",
    "The following code and output provide a simplified view of how rolling forecast horizons work in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_forecast_origin(train, min_train_size, horizon):\n",
    "    '''\n",
    "    Rolling forecast origin generator.\n",
    "    '''\n",
    "    for i in range(len(train) - min_train_size - horizon + 1):\n",
    "        split_train = train[:min_train_size+i]\n",
    "        split_val = train[min_train_size+i:min_train_size+i+horizon]\n",
    "        yield split_train, split_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full training set: [2502, 2414, 2800, 2143, 2708, 1900, 2333, 2222]\n",
      "hidden test set: [1234, 3456]\n"
     ]
    }
   ],
   "source": [
    "full_series = [2502, 2414, 2800, 2143, 2708, 1900, 2333, 2222, 1234, 3456]\n",
    "\n",
    "test = full_series[-2:]\n",
    "train = full_series[:-2]\n",
    "print('full training set: {0}'.format(train))\n",
    "print('hidden test set: {0}'.format(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object rolling_forecast_origin at 0x7fc04d75cc80>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_rolling = rolling_forecast_origin(train, min_train_size=4, horizon=2)\n",
    "cv_rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV[1]\n",
      "Train:\t[2502, 2414, 2800, 2143]\n",
      "Val:\t[2708, 1900]\n",
      "-----\n",
      "CV[2]\n",
      "Train:\t[2502, 2414, 2800, 2143, 2708]\n",
      "Val:\t[1900, 2333]\n",
      "-----\n",
      "CV[3]\n",
      "Train:\t[2502, 2414, 2800, 2143, 2708, 1900]\n",
      "Val:\t[2333, 2222]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for cv_train, cv_val in cv_rolling:\n",
    "    print(f'CV[{i+1}]')\n",
    "    print(f'Train:\\t{cv_train}')\n",
    "    print(f'Val:\\t{cv_val}')\n",
    "    print('-----')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding Window Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(train, window_size, horizon, step=1):\n",
    "    '''\n",
    "    sliding window  generator.\n",
    "    \n",
    "    Parameters:\n",
    "    --------\n",
    "    train: array-like\n",
    "        training data for time series method\n",
    "    \n",
    "    window_size: int\n",
    "        lookback - how much data to include.\n",
    "    \n",
    "    horizon: int\n",
    "        forecast horizon\n",
    "        \n",
    "    step: int, optional (default=1)\n",
    "        step=1 means that a single additional data point is added to the time\n",
    "        series.  increase step to run less splits.\n",
    "        \n",
    "    Returns:\n",
    "        array-like, array-like\n",
    "    \n",
    "        split_training, split_validation\n",
    "    '''\n",
    "    for i in range(0, len(train) - window_size - horizon + 1, step):\n",
    "        split_train = train[i:window_size+i]\n",
    "        split_val = train[i+window_size:window_size+i+horizon]\n",
    "        yield split_train, split_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code tests its with `step=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full training set: [2502, 2414, 2800, 2143, 2708, 1900, 2333, 2222]\n",
      "\n",
      "CV[1]\n",
      "Train:\t[2502, 2414, 2800, 2143]\n",
      "Val:\t[2708]\n",
      "-----\n",
      "CV[2]\n",
      "Train:\t[2414, 2800, 2143, 2708]\n",
      "Val:\t[1900]\n",
      "-----\n",
      "CV[3]\n",
      "Train:\t[2800, 2143, 2708, 1900]\n",
      "Val:\t[2333]\n",
      "-----\n",
      "CV[4]\n",
      "Train:\t[2143, 2708, 1900, 2333]\n",
      "Val:\t[2222]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "cv_sliding = sliding_window(train, window_size=4, horizon=1)\n",
    "\n",
    "print('full training set: {0}\\n'.format(train))\n",
    "\n",
    "i = 0\n",
    "for cv_train, cv_val in cv_sliding:\n",
    "    print(f'CV[{i+1}]')\n",
    "    print(f'Train:\\t{cv_train}')\n",
    "    print(f'Val:\\t{cv_val}')\n",
    "    print('-----')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code tests it with `step=2`.  Note that you get less splits.  The code is less computationally expensive at the cost of less data.  That is probably okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full training set: [2502, 2414, 2800, 2143, 2708, 1900, 2333, 2222]\n",
      "\n",
      "CV[1]\n",
      "Train:\t[2502, 2414, 2800, 2143]\n",
      "Val:\t[2708]\n",
      "-----\n",
      "CV[2]\n",
      "Train:\t[2800, 2143, 2708, 1900]\n",
      "Val:\t[2333]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "cv_sliding = sliding_window(train, window_size=4, horizon=1, step=2)\n",
    "\n",
    "print('full training set: {0}\\n'.format(train))\n",
    "\n",
    "i = 0\n",
    "for cv_train, cv_val in cv_sliding:\n",
    "    print(f'CV[{i+1}]')\n",
    "    print(f'Train:\\t{cv_train}')\n",
    "    print(f'Val:\\t{cv_val}')\n",
    "    print('-----')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Cross Validation Example using Naive1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forecast_tools.baseline import SNaive, Naive1\n",
    "from forecast_tools.datasets import load_emergency_dept\n",
    "#optimised version of the functions above...\n",
    "from forecast_tools.model_selection import (rolling_forecast_origin, \n",
    "                                            sliding_window,\n",
    "                                            cross_validation_score)\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_emergency_dept()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Naive1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit runs the code multiple times to get an estimate of runtime.\n",
    "#comment if out to run the code only once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run on a single core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 812 ms, sys: 0 ns, total: 812 ms\n",
      "Wall time: 809 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = sliding_window(train, window_size=14, horizon=7, step=1)\n",
    "results_1 = cross_validation_score(model, train, cv, mean_absolute_error, \n",
    "                                   n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run across multiple cores by setting `n_jobs=-1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 369 ms, sys: 71.5 ms, total: 440 ms\n",
      "Wall time: 990 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "cv = sliding_window(train, window_size=14, horizon=7, step=1)\n",
    "results_2 = cross_validation_score(model, train, cv, mean_absolute_error,\n",
    "                                    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(324, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(324, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.653439153439148 10.346957901088238\n"
     ]
    }
   ],
   "source": [
    "print(results_1.mean(), results_1.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just to illustrate that the results are the same - the difference is runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.653439153439148 10.346957901088238\n"
     ]
    }
   ],
   "source": [
    "print(results_2.mean(), results_2.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation with multiple forecast horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizons = [7, 14, 21]\n",
    "cv = sliding_window(train, window_size=14, horizon=max(horizons), step=1)\n",
    "#note that we now pass in the horizons list to cross_val_score\n",
    "results_h = cross_validation_score(model, train, cv, mean_absolute_error,\n",
    "                                   horizons=horizons, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7days</th>\n",
       "      <th>14days</th>\n",
       "      <th>21days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.142857</td>\n",
       "      <td>22.357143</td>\n",
       "      <td>23.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.857143</td>\n",
       "      <td>18.285714</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.857143</td>\n",
       "      <td>22.357143</td>\n",
       "      <td>25.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.142857</td>\n",
       "      <td>18.571429</td>\n",
       "      <td>19.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.142857</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>20.142857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       7days     14days     21days\n",
       "0  21.142857  22.357143  23.190476\n",
       "1  14.857143  18.285714  19.000000\n",
       "2  17.857143  22.357143  25.047619\n",
       "3  17.142857  18.571429  19.285714\n",
       "4  23.142857  19.500000  20.142857"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#results are returned as numpy array - easy to cast to dataframe and display\n",
    "pd.DataFrame(results_h, columns=['7days', '14days', '21days']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation example using ARIMA - does it speed up when CV run in Parallel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use ARIMA from pmdarima as that has a similar interface to baseline models.\n",
    "from pmdarima import ARIMA, auto_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ato_model = auto_arima(train, suppress_warnings=True, n_jobs=-1, m=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#auto_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create arima model - reasonably complex model\n",
    "#order=(1, 1, 2), seasonal_order=(2, 0, 2, 7)\n",
    "args = {'order':(1, 1, 2), 'seasonal_order':(2, 0, 2, 7)}\n",
    "model = ARIMA(order=args['order'], seasonal_order=args['seasonal_order'],\n",
    "              enforce_stationarity=False, suppress_warnings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.8 s, sys: 373 ms, total: 40.1 s\n",
      "Wall time: 13.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = rolling_forecast_origin(train, min_train_size=320, horizon=7)\n",
    "results_1 = cross_validation_score(model, train, cv, mean_absolute_error, \n",
    "                                   n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comment out %%timeit to run the code only once!\n",
    "\n",
    "you should see a big improvement in performance.  mine went \n",
    "from 12.3 seconds to 2.4 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.63 s, sys: 252 ms, total: 1.88 s\n",
      "Wall time: 4.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = rolling_forecast_origin(train, min_train_size=320, horizon=7)\n",
    "results_2 = cross_validation_score(model, train, cv, mean_absolute_error, \n",
    "                                   n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.58663509219668"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.586662939018318"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

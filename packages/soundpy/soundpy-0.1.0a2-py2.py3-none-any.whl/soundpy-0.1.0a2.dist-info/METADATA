Metadata-Version: 2.1
Name: soundpy
Version: 0.1.0a2
Summary: A research-based framework for exploring sound as well as machine learning in the context of sound.
Home-page: https://github.com/a-n-rose/Python-Sound-Tool
Author: Aislyn Rose
Author-email: rose.aislyn.noelle@gmail.com
License: AGPL-3.0
Platform: UNKNOWN
Classifier: License :: OSI Approved :: GNU Affero General Public License v3
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.6
Requires-Python: >=3.6.9
Description-Content-Type: text/markdown
Requires-Dist: tensorflow (==2.1.0)
Requires-Dist: tensorflow-estimator (==2.1.0)
Requires-Dist: numpy (==1.19.1)
Requires-Dist: scipy (==1.4.1)
Requires-Dist: scikit-learn (==0.23.2)
Requires-Dist: librosa (==0.8.0)
Requires-Dist: python-speech-features (==0.6)
Requires-Dist: matplotlib (==3.3.0)
Requires-Dist: soundfile (==0.10.3.post1)
Requires-Dist: numba (==0.50.1)

# SoundPy

SoundPy is an experimental framework for exploring sound as well as machine learning in the context of sound. 

[![License](https://img.shields.io/badge/license-GNU%20AGPL-brightgreen)](https://github.com/a-n-rose/Python-Sound-Tool/blob/master/LICENSE.md)
[![PyPI pyversions](https://img.shields.io/badge/python-3.6-yellow)](https://www.python.org/downloads/release/python-360/)


# Documentation

For examples and to navigate the code, see the <a href="https://aislynrose.bitbucket.io/">documentation</a>. 

# Github

You can find the <a href="https://github.com/a-n-rose/Python-Sound-Tool/tree/master">Github repo</a> here.

# Examples 

Explore example code:

### Visually and Aurally in the Documentation:

<a href="https://aislynrose.bitbucket.io/example_cases.html">SoundPy Examples</a> 

### Via Jupyter Notebook 

You can have a look at the notebooks in the repo: <a href="https://github.com/a-n-rose/Python-Sound-Tool/tree/master/jupyter_notebooks">jupyter_notebooks</a>

## Main Uses:

### Visualization
- pre and post filtering
- during feature extraction process 
- various feature types: raw signal vs stft vs fbank vs mfcc
- voice activity in signal
- dominant frequency in signal

### Audio Prep / Manipulation
- convert audiofiles 
- extract features: raw signal, stft, powspec, fbank, mfcc
- augment audio: speed, pitch, add noise, time shift, shuffle, vtlp, harmonic distortion
- filter noise (e.g. wiener filter)
- denoise signal (e.g. with pretrained denoiser model)
- remove non-speech from signal
- identify voice activity in signal
- measure dominant and basic frequencies in signal

### Train and Implement Deep Neural Networks
- cnn model (e.g. sound classifier)
- cnn+lstm model (e.g. speech recognition)
- autoencoder model (e.g. denoiser model)
- pretrained ResNet50 model (e.g. language classifier)

## Requirements

- Python 3.6 (specifically 3.6.9, but other versions should probably work)
- libsndfile1 installed for Linux users 


# Installation

I suggest a virtual environment before installing:
```
$ virtualenv -p python3.6 env
```
or
```
$ python3 -m venv env
```
Then activate the environment
```
$ source env/bin/activate
(env)..$
```

Then install SoundPy via pip:

```
(env)..$ pip install soundpy
```

# About

Note: as is, SoundPy is not yet a stable framework, meaning changes might periodically be made without extreme focus on backwards compatibility. 

Those who might find this useful: 

* speech and sound enthusiasts
* digital signal processing / mathematics / physics / acoustics enthusiasts
* deep learning enthusiasts
* researchers
* linguists
* psycholinguists

The main goal of soundpy is to provide the code and functionality with more context via visualization, research, and mathematics. Most of the resources used to build the functionality stems from publicly available research and datasets. (For a list of open datasets, see my ever growing <a href='https://a-n-rose.github.io/2019/01/06/resources-publicly-available-speech-databases/'>collection</a>.)

As it covers quite a large range, from audio file conversion to implementation of trained neural networks, the purpose of soundpy is not to be the perfect implementation of all functions (although that is also a goal :P ), but rather a peak into how they *can* be implemented, hopefully offering others a foundation for trying out different ways of implementation (feature extraction, building neural networks, etc.).

This project is still in the beginning stages and has a lot of room for growth, especially with contributors having a background / knowlege in data science, computer science, machine and deep learning, physics, acoustics, or dsp. Contributors from other backgrounds are also welcome! If you'd like soundpy to do something it doesn't, try making it or create an issue.

# Example datasets

If you would like to play around with various types of sound, check out my <a href='https://github.com/a-n-rose/mini-audio-datasets'>repo</a> containing mini datasets of sound, ranging from speech to noise. They are very small so don't expect much as it comes to training neural networks. 

# About the Author

I studied clinical linguistics for my master's which introduced me to the inspiring world of open source software, python programming, and the beauty of acoustics. My interests broadened from academic experimental design to the development of tools for identifiying speech irregularities and beyond. Through this I discovered a bit of a missing niche in the Python community: a high-level sound tool for filtering, analysis, **and** deep learning that also offers context to its functionality. You can read more about me and my projects on my <a href="https://a-n-rose.github.io/">blog</a>.

# The Beginnings of SoundPy

This project stemmed from the Prototype Fund project <a href="https://github.com/pgys/NoIze">NoIze</a> which was <a href="https://www.youtube.com/watch?v=BJ0f2x49Imc&feature=youtu.be">presented</a> at PyConDE / PyData Berlin in 2019. This fork broadens the application of the software from smart noise filtering to general sound analysis, filtering, visualization, preparation, etc. Therefore the name has been adapted to more general sound functionality.



# This package will contain the spiders of your Scrapy project
#
# Please refer to the documentation for information on how to create and manage
# your spiders.

import scrapy

from lich_scrapy_random_useragent.items import ExampleItem


class ExampleSpider(scrapy.Spider):
    """ ExampleSpider
    Auto generated by os-scrapy-cookiecuter

    Run:
        scrapy crawl example
    """

    name = "example"

    start_urls = ["http://example.com/"]
    def start_requests(self):
        yield scrapy.Request(
            url="http://www.example.com",
            meta={
                # optional value: random, ie, chrome ...(groups defined in USER_AGENT_FILE)
                "random_ua.type": "random",
                #you can define ua by yourself, it will choose randomly from the list you provided
                "random_ua.user_defined":["Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36","Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2227.1 Safari/537.36"],
            },
            headers={
                'User-Agent':"Scrapy/VERSION (+https://scrapy.org)"
            }
        )

    def parse(self, response):
        request = response.request
        yield ExampleItem(
            request={
                "url": request.url,
                "method": request.method,
                "headers": request.headers,
                "body": request.body,
            },
            response={
                "status": response.status,
                "headers": response.headers,
                "body": response.body,
            },
            meta=response.meta,
        )
